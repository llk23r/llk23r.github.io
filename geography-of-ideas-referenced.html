<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Geography of Ideas</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: Georgia, serif;
            font-size: 17px;
            line-height: 1.6;
            color: #222;
            background: #f8f8f8;
        }
        
        .container {
            width: 100%;
            max-width: none;
            margin: 0 auto;
            padding: 60px 5vw;
            background: white;
        }
        
        h1 {
            font-size: 36px;
            font-weight: normal;
            margin-bottom: 40px;
            text-align: center;
            color: #000;
        }
        
        h2 {
            font-size: 24px;
            font-weight: normal;
            margin: 50px 0 20px 0;
            color: #000;
        }
        
        h3 {
            font-size: 20px;
            font-weight: normal;
            margin: 30px 0 15px 0;
            color: #333;
            font-style: italic;
        }
        
        p {
            margin: 15px 0;
        }
        
        .visualization {
            width: 100%;
            height: 500px;
            margin: 40px 0;
            background: #fafafa;
            border: 1px solid #ddd;
            border-radius: 4px;
            position: relative;
        }
        
        .viz-caption {
            text-align: center;
            font-size: 14px;
            color: #666;
            margin: 10px 0 30px 0;
            font-style: italic;
        }
        
        .viz-controls {
            position: absolute;
            top: 15px;
            left: 15px;
            background: rgba(255, 255, 255, 0.95);
            padding: 15px;
            border-radius: 4px;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-size: 13px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            z-index: 10;
        }
        
        .viz-label {
            position: absolute;
            top: 15px;
            right: 15px;
            background: rgba(255, 255, 255, 0.95);
            padding: 12px 15px;
            border-radius: 4px;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            font-size: 13px;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            z-index: 10;
        }
        
        .control-btn {
            display: block;
            width: 100%;
            padding: 8px 12px;
            margin: 5px 0;
            border: 1px solid #ddd;
            background: white;
            border-radius: 3px;
            cursor: pointer;
            font-size: 12px;
            transition: all 0.2s;
        }
        
        .control-btn:hover {
            background: #f0f0f0;
            border-color: #999;
        }
        
        .control-btn.active {
            background: #000;
            color: white;
            border-color: #000;
        }

        .tooltip {
            position: absolute;
            background: rgba(0, 0, 0, 0.9);
            color: white;
            padding: 12px 16px;
            border-radius: 6px;
            font-size: 14px;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            pointer-events: none;
            z-index: 1000;
            max-width: 300px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.3);
            display: none;
        }

        .tooltip strong {
            color: #4ecdc4;
            display: block;
            margin-bottom: 4px;
            font-size: 16px;
        }

        .node-highlight {
            filter: brightness(1.5) saturate(1.3);
        }

        /* Mobile responsive styles */
        @media (max-width: 768px) {
            .container {
                padding: 20px 15px;
            }

            .visualization {
                height: 350px;
                margin: 30px 0;
            }

            .viz-controls {
                position: static;
                background: rgba(255, 255, 255, 0.95);
                padding: 15px;
                margin-bottom: 15px;
                border-radius: 4px;
                width: 100%;
                box-sizing: border-box;
            }

            .viz-label {
                position: static;
                background: rgba(255, 255, 255, 0.95);
                padding: 12px 15px;
                margin-bottom: 15px;
                border-radius: 4px;
                width: 100%;
                box-sizing: border-box;
                font-size: 12px;
            }

            .control-btn {
                display: inline-block;
                width: auto;
                margin: 0 5px 5px 0;
                padding: 6px 10px;
                font-size: 11px;
            }

            .viz-caption {
                font-size: 13px;
                margin: 8px 0 25px 0;
            }

            .tooltip {
                max-width: 250px;
                font-size: 13px;
                padding: 10px 12px;
            }

            .tooltip strong {
                font-size: 14px;
            }
        }

        @media (max-width: 480px) {
            .visualization {
                height: 280px;
            }

            h1 {
                font-size: 28px;
            }

            .viz-controls {
                padding: 10px;
            }

            .viz-label {
                padding: 10px 12px;
                font-size: 11px;
            }

            .control-btn {
                padding: 5px 8px;
                font-size: 10px;
                margin: 0 3px 3px 0;
            }
        }
        
        .math-definition {
            background: #f5f5f5;
            padding: 20px;
            margin: 25px 0;
            border-left: 3px solid #000;
            font-family: 'Courier New', monospace;
            font-size: 15px;
            line-height: 1.8;
        }
        
        .example-box {
            margin: 25px 0;
            padding-left: 20px;
            border-left: 2px solid #ddd;
        }
        
        .example-box p {
            margin: 8px 0;
        }
        
        .emphasis {
            font-style: italic;
            color: #000;
        }
        
        .footnote {
            font-size: 15px;
            color: #666;
            margin-top: 50px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
        }
        
        .references {
            font-size: 14px;
            color: #666;
            margin-top: 50px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
        }
        
        .references h2 {
            font-size: 20px;
            margin-bottom: 15px;
        }
        
        .references ol {
            margin-left: 20px;
        }
        
        .references li {
            margin: 8px 0;
            line-height: 1.5;
        }
        
        sup {
            font-size: 0.8em;
            vertical-align: super;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>The Geography of Ideas</h1>
        
        <p>I've been thinking about how the world finds answers, and I keep coming back to a spatial model.</p>

        <p>Everything—every idea, skill, technology, cultural practice, and answer—exists as a point in a high-dimensional space. When the world has a question that becomes urgent enough, it searches this space. The search finds what's positioned there.</p>

        <h2>The Model</h2>

        <p>Let me be precise about what I mean. The knowledge space is high-dimensional. Every position in it represents a distinct point in this vast territory. The critical insight is about perspective.</p>

        <p>When you're working on something, you have a <span class="emphasis">local perspective</span>. From your vantage point, you can see who else is working on similar things. You find five, ten, maybe twenty people worldwide doing related work. From where you sit, there's a community. It feels populated.</p>

        <p>But from the <span class="emphasis">world's perspective</span>—looking at all of human knowledge and activity—that same cluster of people may be extraordinarily far from other clusters doing different work. What feels like density locally is sparsity globally. This perspective gap creates a systematic illusion.</p>

        <p>Here's a simplified three-dimensional view:</p>

        <div class="visualization" id="viz1">
            <div class="viz-label">
                <strong>Knowledge Space (K)</strong><br>
                Rotate: drag | Zoom: scroll<br>
                <button class="control-btn" onclick="resetView('viz1')" style="margin-top: 8px;">Reset View</button><br><br>
                <strong>Legend:</strong><br>
                <span style="color: #e74c3c;">●</span> Dense regions (mainstream)<br>
                <span style="color: #3498db;">●</span> Sparse breakthroughs (blue)<br>
                <span style="color: #2ecc71;">●</span> Sparse breakthroughs (green)<br><br>
                <em>Hover nodes for details</em>
            </div>
        </div>
        <div class="viz-caption">
            Figure 1: Red clusters (mainstream ideas) appear dense when viewed locally. Blue/green nodes (breakthroughs) appear sparse—but only until the right question becomes urgent and the search finds them.
        </div>

        <h2>Observer-Relative Coordinates</h2>

        <p>The space has no absolute origin. Perception is always relative to where you stand. This relativity creates systematic illusions about what's real versus what's apparent.</p>

        <p>Say you're working on something and you can see five other people worldwide doing similar work. From your local perspective, you have peers. It feels like there's a community around this work.</p>

        <div class="visualization" id="viz2">
            <div class="viz-controls">
                <div style="margin-bottom: 8px; font-weight: 600;">View From:</div>
                <button class="control-btn active" onclick="switchView('observer')">Your Perspective</button>
                <button class="control-btn" onclick="switchView('world')">World's Perspective</button>
            </div>
        </div>
        <div class="viz-caption">
            Figure 2: Switch perspectives to see how the same space looks different. Yellow = You. Blue = Your visible peers. Gray = The rest of the world's work.
        </div>

        <p>From your local frame of reference: you see five peers nearby. This feels like a community. It feels populated.</p>

        <p>From the world's frame of reference: your entire cluster is extremely distant from the nearest other cluster. You're in genuinely sparse territory—and didn't know it.</p>

        <div class="example-box">
            <p><strong>Example:</strong> In 1973, if you were DJing in the Bronx, you knew maybe 10-15 others doing it. From your position, a scene. From the world's position (all of music, all of culture), completely new territory.<sup>1,2,3</sup></p>
            
            <p>When the question "what comes after disco/soul?" became urgent, the search found that entire cluster. We call what happened next hip hop. DJ Kool Herc's August 11, 1973 party at 1520 Sedgwick Avenue is widely recognized as the birthplace of hip hop, where he introduced techniques that would define the genre.<sup>4,5</sup></p>
        </div>

        <div class="example-box">
            <p><strong>Example:</strong> In the 1980s, neural network research existed in sparse territory. After the first AI winter (1974-1980), funding and interest had declined significantly.<sup>6,7</sup> Researchers like Geoffrey Hinton worked on backpropagation and multi-layer networks during this period, often with limited support.<sup>8,9</sup></p>
            
            <p>When pattern recognition and machine learning questions became urgent in the 2010s, the search found this foundational work, leading to the deep learning revolution.<sup>10</sup></p>
        </div>

        <h2>When Work Looks "Wrong"</h2>

        <p>Here's what trips people up: when you're positioned in sparse territory, it often looks like nobody cares about what you're doing.</p>

        <p>No funding. No media attention. Peers think you're wasting your time. The market doesn't value it. Institutions ignore it. It feels wrong.</p>

        <p>But this is exactly what sparse territory looks like from the inside before the search arrives. The lack of interest isn't evidence you're wrong. It's evidence you're far from dense regions where the current search is operating.</p>

        <p>Gregor Mendel published his pioneering work on heredity in 1866. His findings were largely overlooked for 34 years until three scientists—Hugo de Vries, Carl Correns, and Erich von Tschermak—independently rediscovered his work in 1900, recognizing its fundamental importance to genetics.<sup>9,10,11</sup></p>

        <p>Katalin Karikó worked on mRNA for decades in obscurity. The University of Pennsylvania demoted her in 1995 from her tenure-track position and significantly reduced her salary, as her mRNA research was considered too risky and failed to secure sufficient funding.<sup>12,13</sup> Despite this setback and a cancer diagnosis, she persisted in her research. When COVID-19 made mRNA vaccine technology desperately urgent in 2020, her decades of foundational work with Drew Weissman became the basis for the Pfizer-BioNTech and Moderna vaccines.<sup>14,15</sup></p>

        <p>Vincent van Gogh is known to have sold only one painting during his lifetime—"The Red Vineyard"—which sold for 400 francs at a Brussels exhibition in March 1890, four months before his death.<sup>16,17,18</sup> Post-impressionism was positioned in sparse territory during his lifetime. The search found it decades later.</p>

        <p class="emphasis">If you have depth in your work—if it's complete, coherent, if others can build on it—and you're in genuinely sparse territory, the search will find you when the question becomes urgent enough. This isn't probability. It's inevitability.</p>

        <p>The search has to find you, or it fails at its purpose.</p>

        <p>The feeling of being wrong is just what it feels like to be in position P at distance d from dense regions, before urgency U reaches the threshold that triggers search S in your region.</p>

        <h2>The Search Mechanism</h2>

        <p>Different domains use different search mechanisms:</p>

        <p><strong>Science:</strong> Citation networks, replication, conferences, funding flows</p>

        <p><strong>Technology:</strong> Markets, patents, developer communities, GitHub stars</p>

        <p><strong>Culture:</strong> Media, imitation, social transmission, platforms</p>

        <p><strong>Economics:</strong> Price signals, competition, investment patterns</p>

        <p>But they all exhibit the same pattern: when a question becomes urgent, the mechanism searches the space and finds what's positioned there.</p>

        <h3>Evidence Across Domains</h3>

        <div class="example-box">
            <p><strong>Science—Different Timescales:</strong></p>
            <p>Mendel (1866) → rediscovered (1900). Position sat 34 years until biology needed it.<sup>9,10</sup></p>
            <p>mRNA vaccines: positioned since 1990s, found urgently in 2020.<sup>12,13,14</sup></p>
            <p>CRISPR: CRISPR systems in bacteria were discovered in the 1980s, but the breakthrough for genome editing came in 2012 when Jennifer Doudna and Emmanuelle Charpentier demonstrated CRISPR-Cas9 could be used as programmable genetic scissors.<sup>19,20,21</sup></p>
            <p>Continental drift: Alfred Wegener proposed the theory in 1912, but it was widely rejected due to lack of a convincing mechanism. The theory wasn't accepted until the 1960s when seafloor spreading provided the missing evidence for plate tectonics.<sup>22,23,24</sup></p>
        </div>

        <div class="example-box">
            <p><strong>Technology:</strong></p>
            <p>Personal computers: The Homebrew Computer Club first met in March 1975 in Menlo Park, California, bringing together about 30-50 computer enthusiasts.<sup>25,26</sup> Steve Wozniak and Steve Jobs attended these meetings, where Wozniak showed off the Apple-1. The club was instrumental in launching the personal computing revolution, with mainstream adoption following within 5-10 years.<sup>27</sup></p>
            <p>Internet (TCP/IP): positioned 1960s-70s → found 1990s. 20-30 year lag.</p>
            <p>LLMs: small research cluster post-2017 → found explosively 2022-2023. 5 years.</p>
        </div>

        <div class="example-box">
            <p><strong>Culture:</strong></p>
            <p>Jazz: New Orleans ~1900, small community → global within decades.</p>
            <p>K-pop: positioned in South Korea → found globally via YouTube and social media platforms in the 2010s. PSY's "Gangnam Style" in 2012 became the first YouTube video to reach one billion views, marking K-pop's breakthrough to mainstream global consciousness.<sup>28,29,30</sup></p>
            <p>Yoga: positioned in India for millennia → spread to the West primarily in the 20th century. Swami Vivekananda introduced yoga philosophy to America in 1893, but widespread adoption as a physical practice didn't occur until the mid-20th century, particularly during the 1960s-70s.<sup>31,32,33</sup></p>
        </div>

        <div class="example-box">
            <p><strong>Economics:</strong></p>
            <p>Index funds: John Bogle founded Vanguard in 1974 and introduced the First Index Investment Trust (now Vanguard 500 Index Fund) in 1976—the first index fund available to individual investors.<sup>34,35,36</sup> Initially ridiculed as "un-American" and "Bogle's Folly," index funds were found gradually as investors recognized their benefits, and are now dominant in the investment landscape.</p>
            <p>Bitcoin: emerged from cypherpunk circles when Satoshi Nakamoto released the whitepaper in October 2008 and mined the genesis block in January 2009.<sup>37,38</sup> Found rapidly in tech communities, with slower mainstream adoption.</p>
            <p>Remote work: technology for remote work was positioned for decades, but found urgently in 2020 during the COVID-19 pandemic. The share of workers primarily working from home jumped from 6.5% in 2019 to 32% in May 2020, stabilizing around 12% by 2022.<sup>39,40,41</sup></p>
        </div>

        <div class="example-box">
            <p><strong>Politics & Social Movements:</strong></p>
            <p>Civil disobedience: Mahatma Gandhi developed and demonstrated nonviolent civil disobedience in South Africa and India during the early-to-mid 20th century.<sup>42,43</sup> Martin Luther King Jr. studied Gandhi's methods and applied them to the American civil rights movement. King visited India in 1959 to learn more about Gandhi's philosophy, and the experience strengthened his commitment to nonviolent resistance.<sup>44,45</sup> Gandhi's positioned work was found and adapted by movements worldwide.</p>
            <p>Guerrilla warfare: positioned in theory → found repeatedly (Mao, Castro, Vietnam).</p>
        </div>

        <p>The pattern: deep work in sparse territory gets found when the question becomes urgent. The lag varies (years to centuries), the mechanism varies, but the dynamic holds.</p>

        <h2>Manufacturing Urgency</h2>

        <p>Here's where it gets interesting. You can sometimes influence which questions the world asks.</p>

        <p>Elon Musk didn't wait for "Should we colonize Mars?" to become urgent. He manufactured urgency through demonstration, narrative, media. Forcing the question into consciousness before it would naturally arise.</p>

        <p>Rachel Carson made environmental questions urgent with "Silent Spring," published in 1962. The book documented the environmental harm caused by pesticides like DDT and is widely credited with launching the modern environmental movement.<sup>46,47,48</sup> The questions about environmental harm existed dimly; she made them pressing through rigorous scientific analysis combined with accessible prose.</p>

        <p>Steve Jobs demonstrated "computers as creative tools" and made that question urgent through product and narrative.</p>

        <p>This is different from positioning and waiting. It's positioning and accelerating when the search happens. Requires resources: capital, platform, narrative skill, or extreme visibility.</p>

        <p>Not everyone can do this. But when you can, you're not just positioning in the space—you're influencing the search pattern itself.</p>

        <h2>Modern Visibility</h2>

        <p>Something fundamental changed recently. For most of history, you couldn't see the graph. Buddha didn't know if others were working on consciousness frameworks. Mendel couldn't search "who else studies inheritance?"</p>

        <p>Now you can:</p>

        <p>Search engines show who else works on X globally. GitHub shows all open source projects in a space. Citation databases show related research. Social media shows cultural interest. Google Trends shows questions becoming urgent. Funding patterns are visible.</p>

        <p>This means you can assess sparsity somewhat accurately. Search thoroughly and find only 5-10 similar projects worldwide? Probably genuinely sparse.</p>

        <p>You can track urgency in real-time. Watch questions become pressing through search trends, funding, media coverage.</p>

        <p>You can find your cluster even if geographically distributed. Connect with the other people working on similar things across continents.</p>

        <p>The instruments are vastly better than what anyone before 2000 had. The game has new dimensions.</p>

        <h2>The Core Insight</h2>

        <p>You can't see the full graph. You see your local neighborhood through imperfect instruments.</p>

        <p>If you find a small number of others doing genuinely novel work, you're likely all in sparse territory from the world's perspective, even if it feels populated from yours.</p>

        <p>When you're there and nobody seems to care, that's not evidence you're wrong. That's what sparse territory looks like before the search arrives.</p>

        <p>If your work has depth—if it's complete, coherent, if others can build on it—and the question eventually becomes urgent, the search will find you. Not might find you. Will find you.</p>

        <p>The search operates through different mechanisms (markets, culture, citations) at different speeds (years to centuries), but when sufficient depth exists in sparse territory and urgency arrives, discovery follows a logic that's more about position than luck.</p>

        <p>That's the mental model I keep coming back to. The world asks questions. The search operates. It finds what's positioned in the space with sufficient depth when the question becomes urgent enough.</p>

        <p>Everything we know about was found. The interesting question is how the search operates and what that suggests about positioning.</p>

        <h2>Limitations of the Model</h2>

        <p>This model is powerful but incomplete. It assumes certain conditions that don't always hold:</p>

        <p><strong>Survivorship Bias.</strong> We see the ideas that were found. We don't see the deep work that remained lost due to lack of preservation, missing documents, or genuine unluckiness. Some brilliant work was positioned correctly but never discovered because it wasn't recorded, didn't survive, or the person couldn't persist long enough.</p>

        <p><strong>Depth Is Necessary but Uncertain.</strong> The model assumes that if your work has sufficient depth and you're in sparse territory, search will find you. But depth is hard to judge before discovery. You can't know with certainty if your work is complete enough, coherent enough, buildable enough. This creates real anxiety for people doing novel work.</p>

        <p><strong>Barriers Are Real and Structural.</strong> Geography, language, institutional access, and bias affect whether a search actually reaches sparse regions. A breakthrough in a remote area, in a non-dominant language, or outside prestigious institutions faces additional barriers that the pure spatial model doesn't capture.</p>

        <p><strong>Path Dependence and Paradigms.</strong> The knowledge space isn't static. Discoveries change what's possible next, what's even visible. A paradigm shift can make old work suddenly relevant or permanently obsolete. The search space itself evolves as we discover.</p>

        <p><strong>Urgency Varies Wildly.</strong> What creates urgency in one domain might never create it in another. A question that became urgent for science through war or disease might never become urgent for art through any mechanism. The search operates differently across domains.</p>

        <p>The model explains a real pattern, but it's not a guarantee. It's a framework for thinking about why deep work often gets found, not a promise that yours will be.</p>

        <div class="footnote">
            <p>This essay explores a mental model, not a prescription. The examples show the pattern holds across domains with varying timescales and mechanisms. What doesn't fit teaches us about constraints: preservation matters, paradigms must shift sometimes, social biases affect the search, urgency is non-negotiable.</p>
        </div>
        
        <div class="references">
            <h2>References</h2>
            <ol>
                <li>Britannica. (2023). DJ Kool Herc | Hip-hop, Merry-go-round, History, & Biography.</li>
                <li>Wikipedia. (2003). DJ Kool Herc.</li>
                <li>PBS. Birthplace Of Hip Hop | History Detectives.</li>
                <li>Rolling Stone. (2023). Kool Herc and the History (and Mystery) of Hip-Hop's First Day.</li>
                <li>DW. (2023). How teenagers from the Bronx invented hip-hop 50 years ago.</li>
                <li>Crevier, D. (1993). AI: The Tumultuous History of the Search for Artificial Intelligence. Basic Books.</li>
                <li>NVIDIA Developer. (2022). Deep Learning in a Nutshell: History and Training.</li>
                <li>Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning Representations by Back-Propagating Errors. Nature, 323(6088), 533–536.</li>
                <li>National Institutes of Health. (2002). Mendel—Both Ignored and Forgotten.</li>
                <li>Wikipedia. (2001). Gregor Mendel.</li>
                <li>Genome.gov. (2013). 1900: Rediscovery of Mendel's Work.</li>
                <li>Forbes. (2023). Researcher Demoted By University Of Pennsylvania Wins Nobel Prize.</li>
                <li>Genetic Literacy Project. (2024). After demoting a scientist and cutting her pay, University of Pennsylvania honored for mRNA research used in COVID vaccines.</li>
                <li>Wikipedia. (2020). Katalin Karikó.</li>
                <li>STAO. (2024). The Resilient Journey of Katalin Karikó.</li>
                <li>My Modern Met. (2025). The One Painting van Gogh Is Known to Have Sold During His Lifetime.</li>
                <li>The Art Newspaper. (2025). How did the only painting sold by Van Gogh in his lifetime end up in Russia?</li>
                <li>Artnet News. (2024). The Only Known Painting Van Gogh Sold During His Lifetime.</li>
                <li>Nobel Prize. (2020). Press release: The Nobel Prize in Chemistry 2020.</li>
                <li>PMC. (2022). CRISPR–Cas9: A History of Its Discovery and Ethical Considerations.</li>
                <li>Berkeley News. (2019). CRISPR Timeline.</li>
                <li>American Physical Society. (2025). January 6, 1912: Alfred Wegener Presents His Theory of Continental Drift.</li>
                <li>UC Berkeley Geosciences. (2025). Alfred Wegener's Continental Drift Hypothesis.</li>
                <li>History of Information. (2020). Alfred H. Wegener Proposes the Theory of Continental Drift.</li>
                <li>Wikipedia. (2002). Homebrew Computer Club.</li>
                <li>Cult of Mac. (2025). Today in Apple history: Homebrew Computer Club meets for first time.</li>
                <li>Smithsonian National Museum of American History. (2015). Apple I Microcomputer.</li>
                <li>Hypebae. (2019). A Timeline of How K-Pop Became a Global Phenomenon in the 2010s.</li>
                <li>Wikipedia. (2004). K-pop.</li>
                <li>Korean Cultural Centre UK. (2019). Hallyu (Korean Wave).</li>
                <li>The Whole U - University of Washington. (2021). The Westernization of Yoga.</li>
                <li>Awakened Spirit Yoga. (2023). How Yoga Was Brought to the West.</li>
                <li>Yoga International. (2015). Why We Practice: A Short History of Yoga in the West.</li>
                <li>Vanguard. (2024). Vanguard's history.</li>
                <li>Wikipedia. (2005). John C. Bogle.</li>
                <li>Commoncog. (2025). The Creation of the Index Fund.</li>
                <li>Trust Machines. (2008). Bitcoin in 2009: Genesis Block and the First BTC Transaction.</li>
                <li>Wikipedia. (2010). Satoshi Nakamoto.</li>
                <li>Bureau of Labor Statistics. (2024). The rise in remote work since the pandemic and its impact on productivity.</li>
                <li>Federal Reserve Bank of St. Louis. (2024). The Evolution of Remote Work across Industries.</li>
                <li>Forbes. (2022). The Past, Present And Future Of Remote Work.</li>
                <li>Teach Democracy. (2025). Bringing Down an Empire: Gandhi and Civil Disobedience.</li>
                <li>LINCS. (2019). Martin Luther King Jr.'s use of nonviolence inspired by Gandhi.</li>
                <li>Biography.com. (2021). How Martin Luther King Jr. Took Inspiration From Gandhi on Nonviolent Resistance.</li>
                <li>Westmont College. (2011). Civil Disobedience and the Legacy of Martin Luther King Jr.</li>
                <li>Wikipedia. (2002). Silent Spring.</li>
                <li>Environment & Society Portal. (2020). Silent Spring.</li>
                <li>American Chemical Society. (2023). Legacy of Rachel Carson's Silent Spring.</li>
            </ol>
        </div>
    </div>

    <div id="tooltip" class="tooltip"></div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script>
        // Global reset view function
        function resetView(vizId) {
            if (vizId === 'viz1') {
                const container = document.getElementById('viz1');
                const canvas = container.querySelector('canvas');
                if (canvas && window.viz1Camera) {
                    window.viz1Camera.position.set(80, 80, 80);
                    window.viz1Camera.lookAt(0, 0, 0);
                }
            }
        }

        // Visualization 1: Overall knowledge space
        function createViz1() {
            const container = document.getElementById('viz1');
            const scene = new THREE.Scene();
            scene.background = new THREE.Color(0xfafafa);
            
            const camera = new THREE.PerspectiveCamera(60, container.offsetWidth / container.offsetHeight, 0.1, 2000);
            camera.position.set(80, 80, 80);
            window.viz1Camera = camera; // Store globally for reset function
            
            const renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(container.offsetWidth, container.offsetHeight);
            container.appendChild(renderer.domElement);
            
            // Lighting
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.6);
            scene.add(ambientLight);
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.4);
            directionalLight.position.set(50, 50, 50);
            scene.add(directionalLight);
            
            // Axes (subtle)
            const axesHelper = new THREE.AxesHelper(60);
            axesHelper.material.transparent = true;
            axesHelper.material.opacity = 0.3;
            scene.add(axesHelper);
            
            // Add axis labels
            function createLabel(text, color, position) {
                const canvas = document.createElement('canvas');
                const context = canvas.getContext('2d');
                canvas.width = 128;
                canvas.height = 64;
                context.fillStyle = color;
                context.font = 'Bold 24px Arial';
                context.fillText(text, 40, 40);
                const texture = new THREE.CanvasTexture(canvas);
                const material = new THREE.SpriteMaterial({ map: texture });
                const sprite = new THREE.Sprite(material);
                sprite.scale.set(10, 5, 1);
                sprite.position.copy(position);
                return sprite;
            }
            
            scene.add(createLabel('X', '#ff6b6b', new THREE.Vector3(65, 0, 0)));
            scene.add(createLabel('Y', '#4ecdc4', new THREE.Vector3(0, 65, 0)));
            scene.add(createLabel('Z', '#95e1d3', new THREE.Vector3(0, 0, 65)));
            
            // Create meaningful nodes with labels and tooltips
            function createMeaningfulNode(name, description, x, y, z, color, size = 1) {
                const geometry = new THREE.SphereGeometry(size, 16, 16);
                const material = new THREE.MeshStandardMaterial({
                    color: color,
                    metalness: 0.4,
                    roughness: 0.6,
                    emissive: color,
                    emissiveIntensity: 0.1
                });
                const sphere = new THREE.Mesh(geometry, material);
                sphere.position.set(x, y, z);
                sphere.userData = { name, description, originalColor: color };
                scene.add(sphere);

                // Add label sprite
                const canvas = document.createElement('canvas');
                const context = canvas.getContext('2d');
                canvas.width = 256;
                canvas.height = 64;
                context.fillStyle = '#333';
                context.font = 'Bold 16px Arial';
                context.textAlign = 'center';
                context.fillText(name, 128, 40);
                const texture = new THREE.CanvasTexture(canvas);
                const spriteMaterial = new THREE.SpriteMaterial({ map: texture, transparent: true });
                const sprite = new THREE.Sprite(spriteMaterial);
                sprite.scale.set(15, 3.75, 1);
                sprite.position.set(x, y + size + 2, z);
                scene.add(sprite);

                return sphere;
            }

            // Dense regions (mainstream work) - red clusters
            const denseExamples = [
                { name: "Social Media", desc: "Mainstream platforms, algorithms, engagement metrics", pos: [18, 22, 18] },
                { name: "E-commerce", desc: "Online retail, marketplaces, logistics", pos: [25, 15, 22] },
                { name: "Mobile Apps", desc: "Smartphone applications, app stores", pos: [15, 25, 25] },
                { name: "Cloud Computing", desc: "Infrastructure as service, serverless", pos: [22, 18, 15] },
                { name: "FinTech", desc: "Digital payments, banking apps", pos: [-20, -12, 18] },
                { name: "EdTech", desc: "Online learning platforms", pos: [-28, -18, 12] },
                { name: "HealthTech", desc: "Fitness trackers, health apps", pos: [-22, -8, 20] }
            ];

            const denseNodes = [];
            denseExamples.forEach(ex => {
                denseNodes.push(createMeaningfulNode(ex.name, ex.desc, ex.pos[0], ex.pos[1], ex.pos[2], 0xe74c3c, 0.8));
            });

            // Sparse breakthrough ideas - blue/green nodes
            const sparseExamples = [
                { name: "Hip Hop", desc: "1973 Bronx, DJ Kool Herc - found when disco/soul became urgent", pos: [-45, 30, -20], color: 0x3498db },
                { name: "Neural Networks", desc: "1980s research, Geoffrey Hinton - found for deep learning revolution", pos: [60, -40, 30], color: 0x2ecc71 },
                { name: "mRNA Research", desc: "Katalin Karikó (1990s) - found for COVID vaccines", pos: [-60, 50, -10], color: 0x3498db },
                { name: "Post-Impressionism", desc: "Vincent van Gogh - found decades later", pos: [40, 55, -25], color: 0x2ecc71 },
                { name: "Continental Drift", desc: "Alfred Wegener (1912) - found 1960s for plate tectonics", pos: [-30, -50, 40], color: 0x3498db },
                { name: "CRISPR", desc: "1980s bacteria research - found 2012 for genome editing", pos: [55, 20, -35], color: 0x2ecc71 },
                { name: "Index Funds", desc: "John Bogle (1976) - found gradually as investors recognized benefits", pos: [-40, -30, -30], color: 0x3498db },
                { name: "Bitcoin", desc: "Satoshi Nakamoto (2008) - found rapidly in tech communities", pos: [30, -55, -15], color: 0x2ecc71 },
                { name: "Homebrew Computing", desc: "1975 Silicon Valley - launched personal computing revolution", pos: [-55, 15, 35], color: 0x3498db },
                { name: "K-pop", desc: "South Korea - found globally via YouTube in 2010s", pos: [45, -20, 45], color: 0x2ecc71 },
                { name: "Yoga in West", desc: "Ancient India - spread 20th century, Swami Vivekananda", pos: [-35, 40, -40], color: 0x3498db },
                { name: "Civil Disobedience", desc: "Mahatma Gandhi - adapted by MLK for civil rights", pos: [50, 35, 20], color: 0x2ecc71 }
            ];

            const sparseNodes = [];
            sparseExamples.forEach(ex => {
                sparseNodes.push(createMeaningfulNode(ex.name, ex.desc, ex.pos[0], ex.pos[1], ex.pos[2], ex.color, 1.2));
            });

            // Add some generic background nodes for density
            for (let i = 0; i < 25; i++) {
                const geometry = new THREE.SphereGeometry(0.4, 12, 12);
                const material = new THREE.MeshStandardMaterial({
                    color: 0xe74c3c,
                    metalness: 0.3,
                    roughness: 0.7,
                    transparent: true,
                    opacity: 0.6
                });
                const sphere = new THREE.Mesh(geometry, material);
                sphere.position.set(
                    20 + (Math.random() - 0.5) * 15,
                    20 + (Math.random() - 0.5) * 15,
                    20 + (Math.random() - 0.5) * 15
                );
                scene.add(sphere);
            }

            for (let i = 0; i < 20; i++) {
                const geometry = new THREE.SphereGeometry(0.4, 12, 12);
                const material = new THREE.MeshStandardMaterial({
                    color: 0xe74c3c,
                    metalness: 0.3,
                    roughness: 0.7,
                    transparent: true,
                    opacity: 0.6
                });
                const sphere = new THREE.Mesh(geometry, material);
                sphere.position.set(
                    -25 + (Math.random() - 0.5) * 12,
                    -15 + (Math.random() - 0.5) * 12,
                    15 + (Math.random() - 0.5) * 12
                );
                scene.add(sphere);
            }

            // Interaction setup
            const tooltip = document.getElementById('tooltip');
            const raycaster = new THREE.Raycaster();
            const mouse = new THREE.Vector2();
            let hoveredNode = null;
            let allNodes = [...denseNodes, ...sparseNodes];

            // Mouse interaction handlers
            function onMouseMove(event) {
                const rect = renderer.domElement.getBoundingClientRect();
                mouse.x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
                mouse.y = -((event.clientY - rect.top) / rect.height) * 2 + 1;

                raycaster.setFromCamera(mouse, camera);
                const intersects = raycaster.intersectObjects(allNodes);

                // Reset previous hover
                if (hoveredNode) {
                    hoveredNode.material.emissive.setHex(hoveredNode.userData.originalColor);
                    hoveredNode.material.emissiveIntensity = 0.1;
                }

                if (intersects.length > 0) {
                    const node = intersects[0].object;
                    hoveredNode = node;

                    // Highlight node
                    node.material.emissive.setHex(0xffffff);
                    node.material.emissiveIntensity = 0.3;

                    // Show tooltip
                    tooltip.innerHTML = `<strong>${node.userData.name}</strong>${node.userData.description}`;
                    tooltip.style.display = 'block';
                    tooltip.style.left = event.clientX + 15 + 'px';
                    tooltip.style.top = event.clientY - 10 + 'px';

                    renderer.domElement.style.cursor = 'pointer';
                } else {
                    hoveredNode = null;
                    tooltip.style.display = 'none';
                    renderer.domElement.style.cursor = 'default';
                }
            }

            function onMouseClick(event) {
                const rect = renderer.domElement.getBoundingClientRect();
                mouse.x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
                mouse.y = -((event.clientY - rect.top) / rect.height) * 2 + 1;

                raycaster.setFromCamera(mouse, camera);
                const intersects = raycaster.intersectObjects(allNodes);

                if (intersects.length > 0) {
                    const node = intersects[0].object;
                    // Could add more detailed view or navigation here
                    console.log('Clicked:', node.userData.name);
                }
            }

            renderer.domElement.addEventListener('mousemove', onMouseMove);
            renderer.domElement.addEventListener('click', onMouseClick);

            // Mouse controls
            let isDragging = false;
            let previousMouse = { x: 0, y: 0 };

            renderer.domElement.addEventListener('mousedown', (e) => {
                isDragging = true;
                previousMouse = { x: e.clientX, y: e.clientY };
            });
            
            renderer.domElement.addEventListener('mousemove', (e) => {
                if (isDragging) {
                    const deltaX = e.clientX - previousMouse.x;
                    const deltaY = e.clientY - previousMouse.y;
                    scene.rotation.y += deltaX * 0.01;
                    scene.rotation.x += deltaY * 0.01;
                    previousMouse = { x: e.clientX, y: e.clientY };
                }
            });
            
            renderer.domElement.addEventListener('mouseup', () => isDragging = false);
            renderer.domElement.addEventListener('wheel', (e) => {
                e.preventDefault();
                const zoomSpeed = 0.001;
                const minDistance = 30;
                const maxDistance = 200;

                const currentDistance = camera.position.length();
                const zoomFactor = 1 + e.deltaY * zoomSpeed;

                camera.position.multiplyScalar(zoomFactor);

                // Clamp zoom distance
                const newDistance = camera.position.length();
                if (newDistance < minDistance) {
                    camera.position.normalize().multiplyScalar(minDistance);
                } else if (newDistance > maxDistance) {
                    camera.position.normalize().multiplyScalar(maxDistance);
                }
            });

            // Animation
            function animate() {
                requestAnimationFrame(animate);
                if (!isDragging) scene.rotation.y += 0.002;
                camera.lookAt(0, 0, 0);
                renderer.render(scene, camera);
            }
            animate();
            
            // Resize handler
            window.addEventListener('resize', () => {
                camera.aspect = container.offsetWidth / container.offsetHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(container.offsetWidth, container.offsetHeight);
            });
        }
        
        // Visualization 2: Observer-relative view
        let currentView = 'observer';
        
        function createViz2() {
            const container = document.getElementById('viz2');
            const scene = new THREE.Scene();
            scene.background = new THREE.Color(0xfafafa);
            
            const camera = new THREE.PerspectiveCamera(60, container.offsetWidth / container.offsetHeight, 0.1, 2000);
            camera.position.set(60, 60, 60);
            
            const renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(container.offsetWidth, container.offsetHeight);
            container.appendChild(renderer.domElement);
            
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.6);
            scene.add(ambientLight);
            const directionalLight = new THREE.DirectionalLight(0xffffff, 0.4);
            directionalLight.position.set(50, 50, 50);
            scene.add(directionalLight);
            
            // Observer position
            const observerPos = new THREE.Vector3(-30, 20, 15);
            
            // You (observer)
            const youGeometry = new THREE.SphereGeometry(2, 32, 32);
            const youMaterial = new THREE.MeshStandardMaterial({ 
                color: 0xffd700,
                emissive: 0xffd700,
                emissiveIntensity: 0.3,
                metalness: 0.8,
                roughness: 0.2
            });
            const you = new THREE.Mesh(youGeometry, youMaterial);
            you.position.copy(observerPos);
            scene.add(you);
            
            // Your peers (small cluster)
            const peers = [];
            for (let i = 0; i < 6; i++) {
                const geometry = new THREE.SphereGeometry(1, 16, 16);
                const material = new THREE.MeshStandardMaterial({ 
                    color: 0x3498db,
                    metalness: 0.5,
                    roughness: 0.5
                });
                const peer = new THREE.Mesh(geometry, material);
                peer.position.set(
                    observerPos.x + (Math.random() - 0.5) * 20,
                    observerPos.y + (Math.random() - 0.5) * 20,
                    observerPos.z + (Math.random() - 0.5) * 20
                );
                peer.visible = currentView === 'observer';
                scene.add(peer);
                peers.push(peer);
            }
            
            // Lines to peers (only visible in observer view)
            const lines = [];
            peers.forEach(peer => {
                const geometry = new THREE.BufferGeometry().setFromPoints([
                    observerPos,
                    peer.position
                ]);
                const material = new THREE.LineBasicMaterial({ 
                    color: 0x3498db,
                    transparent: true,
                    opacity: 0.3
                });
                const line = new THREE.Line(geometry, material);
                line.visible = currentView === 'observer';
                scene.add(line);
                lines.push(line);
            });
            
            // Rest of world (many points far away)
            const worldPoints = [];
            for (let i = 0; i < 100; i++) {
                const geometry = new THREE.SphereGeometry(0.5, 8, 8);
                const material = new THREE.MeshStandardMaterial({ 
                    color: 0xcccccc,
                    metalness: 0.3,
                    roughness: 0.7
                });
                const point = new THREE.Mesh(geometry, material);
                
                let x, y, z;
                do {
                    x = (Math.random() - 0.5) * 150;
                    y = (Math.random() - 0.5) * 150;
                    z = (Math.random() - 0.5) * 150;
                } while (
                    Math.sqrt(Math.pow(x - observerPos.x, 2) + 
                             Math.pow(y - observerPos.y, 2) + 
                             Math.pow(z - observerPos.z, 2)) < 50
                );
                
                point.position.set(x, y, z);
                point.visible = currentView === 'world';
                scene.add(point);
                worldPoints.push(point);
            }
            
            // Switch view function
            window.switchView = function(view) {
                currentView = view;
                
                // Update button states
                document.querySelectorAll('.control-btn').forEach(btn => {
                    btn.classList.remove('active');
                });
                event.target.classList.add('active');
                
                if (view === 'observer') {
                    peers.forEach(p => p.visible = true);
                    lines.forEach(l => l.visible = true);
                    worldPoints.forEach(p => p.visible = false);
                    camera.position.set(observerPos.x + 30, observerPos.y + 30, observerPos.z + 30);
                } else {
                    peers.forEach(p => p.visible = false);
                    lines.forEach(l => l.visible = false);
                    worldPoints.forEach(p => p.visible = true);
                    camera.position.set(0, 80, 80);
                }
            };
            
            // Mouse controls
            let isDragging = false;
            let previousMouse = { x: 0, y: 0 };
            
            renderer.domElement.addEventListener('mousedown', (e) => {
                isDragging = true;
                previousMouse = { x: e.clientX, y: e.clientY };
            });
            
            renderer.domElement.addEventListener('mousemove', (e) => {
                if (isDragging) {
                    const deltaX = e.clientX - previousMouse.x;
                    const deltaY = e.clientY - previousMouse.y;
                    scene.rotation.y += deltaX * 0.01;
                    scene.rotation.x += deltaY * 0.01;
                    previousMouse = { x: e.clientX, y: e.clientY };
                }
            });
            
            renderer.domElement.addEventListener('mouseup', () => isDragging = false);
            renderer.domElement.addEventListener('wheel', (e) => {
                e.preventDefault();
                camera.position.multiplyScalar(1 + e.deltaY * 0.001);
            });
            
            // Animation
            function animate() {
                requestAnimationFrame(animate);
                if (!isDragging) scene.rotation.y += 0.002;
                
                if (currentView === 'observer') {
                    camera.lookAt(observerPos);
                } else {
                    camera.lookAt(0, 0, 0);
                }
                
                renderer.render(scene, camera);
            }
            animate();
            
            window.addEventListener('resize', () => {
                camera.aspect = container.offsetWidth / container.offsetHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(container.offsetWidth, container.offsetHeight);
            });
        }
        
        // Initialize when page loads
        window.addEventListener('load', () => {
            createViz1();
            createViz2();
        });
    </script>
</body>
</html>